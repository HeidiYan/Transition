{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "C:\\Anaconda3\\lib\\site-packages\\theano\\configdefaults.py:560: UserWarning: DeprecationWarning: there is no c++ compiler.This is deprecated and with Theano 0.11 a c++ compiler will be mandatory\n",
      "  warnings.warn(\"DeprecationWarning: there is no c++ compiler.\"\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.io as sio\n",
    "\n",
    "import pymc3 as pm\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_data(sub_id):\n",
    "    subdata=mydata[mydata.Subject==sub_id]\n",
    "    #trialindex=list(subdata['trialindex'])\n",
    "    phase=list(subdata['Block'])\n",
    "    conds=list(subdata['Type'])\n",
    "    rt=list(subdata['RT'])\n",
    "    print('The trial length of sub%02d is %d' %(sub_id,len(phase)))\n",
    "    return rt,phase,conds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def do_sampling_random_switchpoint(sub_id,rt,phase,conds,fakesp):\n",
    "    # use empirical mean (ignoring condition or time point) as center of prior\n",
    "    mu_obs = np.mean(rt)\n",
    "    sd_obs = np.std(rt)\n",
    "    \n",
    "    model = pm.Model()\n",
    "    with model:\n",
    "       #mu_new is the mean RT of random stimulus\n",
    "        mu_new = pm.Normal('mu_new', mu=mu_obs, sd=sd_obs*2, testval=mu_obs)\n",
    "        mu_before_old_benefit=pm.Normal('mu_before_old_benefit', mu=mu_obs, sd=sd_obs*2, testval=mu_obs)\n",
    "        mu_before = pm.math.switch(conds, mu_new-mu_before_old_benefit, mu_new)\n",
    "        # RTs after switchpoint come from normal distribution where mean depends on\n",
    "        # condition\n",
    "        mu_after_old_benefit=pm.Normal('mu_after_old_benefit', mu=mu_obs, sd=sd_obs*2, testval=mu_obs)\n",
    "        #theano.tensor，switch(cond, ift, iff)，if cond then ift else iff\n",
    "        mu_after = pm.math.switch(conds, mu_new-mu_after_old_benefit, mu_new)\n",
    "        a=np.arange(fakesp,fakesp+1)\n",
    "        switchpoint=a.repeat(len(phase)) \n",
    "        print('The fake switchpoint of sub%02d is %d' %(sub_id,fakesp))\n",
    "        #if trial in or after the switchpoint session，mu=mu_after，else mu=mu_before\n",
    "        mu = pm.math.switch(phase > switchpoint-1, mu_after, mu_before)\n",
    "        \n",
    "        sigma = pm.HalfNormal('sigma', sd=sd_obs*2, testval=sd_obs*2)\n",
    "           #model construction\n",
    "        rt_modelled = pm.Normal('rt_modelled', mu=mu, sd=sigma, observed=rt)\n",
    "        \n",
    "        step = pm.Metropolis()\n",
    "        \n",
    "        trace = pm.sample(40000, step=step, start=model.test_point, chains=4,cores=4)#MCMC\n",
    "    \n",
    "    return trace[20000::5], model#delete the first 20000 samples(burn-in)，take every fifth of the remaining samples(thining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_sampling_given_switchpoint(sub_id,rt,phase, conds,sp):\n",
    "    # use empirical mean (ignoring condition or time point) as center of prior\n",
    "    mu_obs = np.mean(rt)\n",
    "    sd_obs = np.std(rt)\n",
    "    \n",
    "    model = pm.Model()\n",
    "    with model:\n",
    "        # RTs before switchpoint all come from same distribution\n",
    "        mu_new = pm.Normal('mu_new', mu=mu_obs, sd=sd_obs*2, testval=mu_obs)\n",
    "        mu_before_old_benefit=pm.Normal('mu_before_old_benefit', mu=mu_obs, sd=sd_obs*2, testval=mu_obs)\n",
    "        mu_before = pm.math.switch(conds, mu_new-mu_before_old_benefit, mu_new)\n",
    "        # RTs after switchpoint come from normal distribution where mean depends on\n",
    "        # condition\n",
    "        mu_after_old_benefit=pm.Normal('mu_after_old_benefit', mu=mu_obs, sd=sd_obs*2, testval=mu_obs)\n",
    "        #theano.tensor，switch(cond, ift, iff)，if cond then ift else iff\n",
    "        mu_after = pm.math.switch(conds, mu_new-mu_after_old_benefit, mu_new)\n",
    "        a=np.arange(sp,sp+1)\n",
    "        switchpoint=a.repeat(len(phase)) \n",
    "        print('The true switchpoint of sub%02d is %d' %(sub_id,sp))\n",
    "        mu = pm.math.switch(phase >switchpoint-1, mu_after, mu_before)\n",
    "        \n",
    "        sigma = pm.HalfNormal('sigma', sd=sd_obs*2, testval=sd_obs*2)\n",
    "        rt_modelled = pm.Normal('rt_modelled', mu=mu, sd=sigma, observed=rt)\n",
    "        \n",
    "        step = pm.Metropolis()\n",
    "        \n",
    "        trace = pm.sample(40000, step=step, start=model.test_point, chains=4,cores=4)\n",
    "\n",
    "    return trace[20000::5], model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_sampling_noswitchpoint(sub_id,rt, phase, conds):\n",
    "    # use empirical mean (ignoring condition or time point) as center of prior\n",
    "    mu_obs = np.mean(rt)\n",
    "    sd_obs = np.std(rt)\n",
    "    \n",
    "    model = pm.Model()\n",
    "    with model:\n",
    "        mu_new =  pm.Normal('mu_new', mu=mu_obs, sd=sd_obs*2, testval=mu_obs)\n",
    "        mu_old_benefit =  pm.Normal('mu_old_benefit', mu=mu_obs, sd=sd_obs*2, testval=mu_obs)\n",
    "        sigma = pm.HalfNormal('sigma', sd=sd_obs*2, testval=sd_obs*2)\n",
    "        \n",
    "        mu = pm.math.switch(conds, mu_new-mu_old_benefit, mu_new)\n",
    "        \n",
    "        rt_modelled = pm.Normal('rt_modelled', mu=mu, sd=sigma, observed=rt)\n",
    "        \n",
    "        step = pm.Metropolis()\n",
    "        \n",
    "        trace = pm.sample(40000, step=step, start=model.test_point, chains=4,cores=4)\n",
    "    return trace[20000::5], model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_construct(sub_id,model_type,sp):\n",
    "        rt,phase,conds=get_data(sub_id)\n",
    "        logrt=np.log10(rt)\n",
    "        plt.scatter(list(range(1,len(logrt)+1)),logrt)\n",
    "        plt.savefig(filepath+'/scatter_sub{:02d}.png'.format(sub_id))\n",
    "        print(\"Now is fitting %s model for sub%02d......\"%(model_type,sub_id))\n",
    "        if model_type=='nosp':\n",
    "            trace,model=do_sampling_noswitchpoint(sub_id,logrt,phase,conds)\n",
    "        elif model_type=='randomsp':\n",
    "            trace,model=do_sampling_random_switchpoint(sub_id,logrt,phase,conds,sp)\n",
    "        elif model_type=='givensp':\n",
    "            trace,model=do_sampling_given_switchpoint(sub_id,logrt,phase,conds,sp)\n",
    "        with model:\n",
    "            pm.traceplot(trace)\n",
    "            plt.savefig(filepath+'/{}_trace_sub{:02d}.png'.format(model_type, sub_id))\n",
    "            plt.close('all')\n",
    "            \n",
    "            pm.plot_posterior(trace)\n",
    "            plt.savefig(filepath+'/{}_posterior_sub{:02d}.png'.format(model_type, sub_id))\n",
    "            plt.close('all')\n",
    "              \n",
    "            #export data\n",
    "            with gzip.open(filepath + '/tracedata/{}_trace_sub{:02d}.pkl.gz'.format(model_type, sub_id), 'wb') as f:\n",
    "                pickle.dump((trace, model), f)\n",
    "            waic=pm.waic(trace,scale='deviance')\n",
    "        print(\"The WAIC of %s model is %f\"%(model_type,waic.waic))\n",
    "        print(\"--------------------------------------------------------\")\n",
    "        return trace,model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(sub_id,sp,fakesp):\n",
    "    tracenp,modelnp=model_construct(sub_id,'nosp',sp)\n",
    "    tracegp,modelgp=model_construct(sub_id,'givensp',sp)\n",
    "    tracerp,modelrp=model_construct(sub_id,'randomsp',fakesp)\n",
    "    with pd.ExcelWriter(filepath+'/summary_sub'+str(sub_id)+'.xlsx') as writer: \n",
    "        with modelnp:\n",
    "            pm.summary(tracenp).to_excel(writer, sheet_name='noswitchpoint')\n",
    "           \n",
    "        with modelgp:\n",
    "            pm.summary(tracegp).to_excel(writer, sheet_name='givenswtichpoint')\n",
    "\n",
    "        with modelrp:\n",
    "            pm.summary(tracerp).to_excel(writer, sheet_name='randomswitchpoint')\n",
    "    df_comp_WAIC = pm.compare({'randomswitchpoint': tracerp,'noswitchpoint': tracenp,'givenswitchpoint':tracegp},ic='waic',scale='deviance')\n",
    "    df_comp_WAIC.to_csv(filepath+'/cmp_waic_sub'+str(sub_id)+'.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{44: 6, 48: 5, 50: 4, 56: 5, 57: 4, 58: 4, 61: 5, 64: 4, 65: 5, 66: 4, 68: 4, 71: 6, 75: 7}\n",
      "{44: 3, 48: 3, 50: 6, 56: 7, 57: 7, 58: 3, 61: 4, 64: 3, 65: 6, 66: 3, 68: 5, 71: 4, 75: 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tpdata=pd.read_csv('E:/transition-upload/Python/Bayesian model/experiment1/exp1_tp.csv')\n",
    "tpdata.subject=(tpdata['subject']).astype(int)\n",
    "tpdata.transition_Phase=(tpdata['true_transition']).astype(int)\n",
    "tpdict =tpdata.set_index('subject')['true_transition'].to_dict()\n",
    "print(tpdict)\n",
    "ftpdict =tpdata.set_index('subject')['fake_transition'].to_dict()\n",
    "print(ftpdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Subject  Block  Session  ACC  Type     RT  trailindex\n",
      "0            1      1        1    1  True  503.0           1\n",
      "1            1      1        1    1  True  526.0           2\n",
      "2            1      1        1    1  True  736.0           3\n",
      "3            1      1        1    1  True  576.0           4\n",
      "4            1      1        1    1  True  676.0           5\n",
      "...        ...    ...      ...  ...   ...    ...         ...\n",
      "22195       78      9        9    1  True  343.0         544\n",
      "22196       78      9        9    1  True  377.0         545\n",
      "22197       78      9        9    1  True  423.0         546\n",
      "22198       78      9        9    1  True  382.0         547\n",
      "22199       78      9        9    1  True  450.0         548\n",
      "\n",
      "[21546 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "#read RT data\n",
    "mydata=pd.read_csv('E:/transition-upload/Python/Bayesian model/experiment1/exp1_expdata.csv')\n",
    "#delete NULL data（trials that ACC=0）\n",
    "mydata.dropna(axis=0,how='any',inplace=True)\n",
    "print(mydata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output filepath\n",
    "filepath='E:/transition-upload/Python/Bayesian model/experiment1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The subject is not in the list\n"
     ]
    }
   ],
   "source": [
    "#run\n",
    "subid=1\n",
    "if subid in tpdict.keys():\n",
    "    run(subid,sp=tpdict[subid],fakesp=ftpdict[subid])\n",
    "else:\n",
    "    print(\"The subject is not in the list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
